# Follow The Goat - Project Rules

## Project Overview
This project uses a **PostgreSQL-only architecture** for all data storage and retrieval.

---

### DuckDB Exceptions for Read-Only Caching

**IMPORTANT:** There are TWO exceptions to the PostgreSQL-only rule:

1. **`core/filter_cache.py`** â€” DuckDB read-only cache for filter analysis data.
2. **`000trading/pump_signal_logic.py`** â€” DuckDB read-only cache for pump model trail data.

Both follow the same approved pattern:
- Speeds up analysis by 10-50x vs raw PostgreSQL queries
- Uses DuckDB purely as a read-only cache (rolling window)
- PostgreSQL remains the source of truth
- Cache is automatically synced incrementally from PostgreSQL (watermark-based)
- NO other modules should use DuckDB


## ğŸš¨ COMPONENT-BASED ARCHITECTURE ğŸš¨

**EACH COMPONENT RUNS AS A SEPARATE PROCESS**

### run_component.py - Per-Component Runner
Each scheduler component runs as an independent process via `run_component.py`:

```bash
python3 scheduler/run_component.py --component fetch_jupiter_prices
python3 scheduler/run_component.py --component follow_the_goat
```

**Features:**
- PostgreSQL advisory lock (only ONE instance per component)
- Enable/disable toggle via dashboard
- Heartbeat reporting for health monitoring
- Automatic error logging

### Component Types

**Data Ingestion (former master.py):**
- `fetch_jupiter_prices` - Jupiter API prices (every 1s)
- `sync_trades_from_webhook` - Trade sync (every 1s)
- `process_price_cycles` - Price cycle detection (every 2s)
- `webhook_server` - FastAPI webhook (port 8001)
- `php_server` - PHP website (port 8000)
- `binance_stream` - Order book stream

**Trading Logic (former master2.py):**
- `follow_the_goat` - Wallet tracker (every 1s)
- `trailing_stop_seller` - Trailing stops (every 1s)
- `train_validator` - Trade validation (every 20s)
- `update_potential_gains` - Gains calculation (every 15s)
- `create_new_patterns` - Pattern generation (every 10 min)
- `create_profiles` - Wallet profiles (every 30s)
- `archive_old_data` - Data archival (hourly)
- `restart_quicknode_streams` - Stream monitoring (every 15s)
- `local_api_5052` - Local API (port 5052)

**How Data Flows:**
```
run_component.py processes â†’ PostgreSQL â† website_api.py (port 5051)
```

### Dashboard Control
Components can be enabled/disabled via the Scheduler Metrics dashboard.
Toggle takes effect within 5 seconds (heartbeat interval).

**âœ… Each component can restart independently - all data persists in PostgreSQL**

---

## Database: PostgreSQL Only

### Single Source of Truth
- **One PostgreSQL database** for everything
- No hot/cold storage split
- No in-memory caching
- No data syncing between processes

### Connection Management
```python
from core.database import get_postgres, postgres_execute, postgres_query

# Read data
with get_postgres() as conn:
    with conn.cursor() as cursor:
        cursor.execute("SELECT * FROM prices WHERE token = %s", ['SOL'])
        results = cursor.fetchall()  # Returns list of dicts

# Write data
postgres_execute(
    "INSERT INTO prices (timestamp, token, price) VALUES (NOW(), %s, %s)",
    ['SOL', 123.45]
)
```

### Connection Pooling
- `psycopg2.pool.SimpleConnectionPool` (5-20 connections)
- Thread-safe
- Automatic connection management via context managers
- No manual connection cleanup needed

---

## Core Principles

### 1. Clean Code
- Minimal files - consolidate where possible
- Clear, descriptive naming
- Single responsibility per module
- No duplicate code across features

### 2. Database Access Patterns

**Reading Data:**
```python
from core.database import get_postgres

with get_postgres() as conn:
    with conn.cursor() as cursor:
        cursor.execute("""
            SELECT price, timestamp FROM prices 
            WHERE token = %s 
            ORDER BY timestamp DESC LIMIT 1
        """, ['SOL'])
        result = cursor.fetchone()
```

**Writing Data:**
```python
from core.database import postgres_execute

rows_affected = postgres_execute(
    "UPDATE follow_the_goat_buyins SET our_status = %s WHERE id = %s",
    ['sold', 123]
)
```

**Bulk Insert:**
```python
from core.database import postgres_insert_many

postgres_insert_many("prices", [
    {"timestamp": ts1, "token": "SOL", "price": 123.45},
    {"timestamp": ts2, "token": "BTC", "price": 50000.00},
])
```

### 3. Important SQL Syntax Differences

**Parameter Placeholders:**
```python
# âœ… CORRECT (PostgreSQL)
cursor.execute("SELECT * FROM table WHERE id = %s", [123])

# âŒ WRONG (DuckDB syntax - don't use)
cursor.execute("SELECT * FROM table WHERE id = ?", [123])
```

**Upsert:**
```python
# PostgreSQL
cursor.execute("""
    INSERT INTO table (id, val) VALUES (%s, %s)
    ON CONFLICT (id) DO UPDATE SET val = EXCLUDED.val
""", [1, 'x'])

cursor.execute("""
    INSERT INTO table (id, val) VALUES (%s, %s)
    ON CONFLICT DO NOTHING
""", [1, 'x'])
```

**Data Types:**
- Use `BIGSERIAL` for auto-increment primary keys
- Use `DOUBLE PRECISION` for decimals
- Use `JSONB` for JSON columns
- Use `SMALLINT` for small integers
- Use `BOOLEAN` for flags
- Use `INTERVAL '24 hours'` for time arithmetic

### 4. Scheduling: run_component.py
- **NEVER use .bat files** for scheduling Python scripts
- Each job runs as a separate process via `scheduler/run_component.py`
- Jobs are defined in `scheduler/jobs.py`
- Component registry in `scheduler/component_registry.py`

```python
# To add a new job:
# 1. Add the job function to scheduler/jobs.py
# 2. Register it in scheduler/component_registry.py
# 3. Add it to _interval_job_specs() in scheduler/run_component.py
# 4. Start it: python3 scheduler/run_component.py --component my_new_job
```

---

## Port Assignments

| Port | Service | Master | Purpose |
|------|---------|--------|---------|
| 5051 | Flask Website API | website_api.py | Serves website data from PostgreSQL |
| 5052 | FastAPI Local API | master2.py | Trading logic queries |
| 8000 | PHP Server | master.py | Website frontend |
| 8001 | FastAPI Webhook | master.py | Receives trade data from QuickNode |

---

## Project Structure

```
follow_the_goat/
â”œâ”€â”€ .cursorrules # This file - READ THIS FIRST
â”œâ”€â”€ core/ # Shared utilities
â”‚ â”œâ”€â”€ database.py # PostgreSQL connection manager
â”‚ â”œâ”€â”€ config.py # Environment and settings
â”‚ â””â”€â”€ logging.py # Centralized logging
â”œâ”€â”€ scheduler/ # APScheduler masters
â”‚ â”œâ”€â”€ master.py # DATA ENGINE - raw data ingestion
â”‚ â”œâ”€â”€ master2.py # TRADING LOGIC - all computations
â”‚ â”œâ”€â”€ website_api.py # Website API (Flask, port 5051)
â”‚ â””â”€â”€ status.py # Job status tracking (shared)
â”œâ”€â”€ features/ # Individual feature modules
â”‚ â””â”€â”€ [feature_name]/ # One folder per feature
â”œâ”€â”€ scripts/ # Database migration scripts
â”‚ â””â”€â”€ postgres_schema.sql # Complete PostgreSQL schema
â””â”€â”€ 000trading/ # Trading modules
```

---

## Adding New Components

### To add a new job:
1. Add the job function to `scheduler/jobs.py`
2. Register it in `scheduler/component_registry.py` (ComponentDef)
3. Add it to `_interval_job_specs()` in `scheduler/run_component.py`
4. Start it: `python3 scheduler/run_component.py --component my_new_job`

### To add a new service (long-running):
1. Add start/stop functions to `scheduler/jobs.py`
2. Register it in `scheduler/component_registry.py`
3. Add it to `_service_specs()` in `scheduler/run_component.py`

**Rule of Thumb:** Jobs run periodically, Services run continuously.

---

## Database Conventions

### Required Columns
Every table should have:
- `id`: BIGSERIAL PRIMARY KEY (or SERIAL for smaller tables)
- `created_at` or `timestamp`: TIMESTAMP DEFAULT CURRENT_TIMESTAMP

### Indexes
Always create indexes on:
- Timestamp columns used in queries
- Foreign key relationships
- Columns used in WHERE clauses

---

## Code Patterns

### Feature Module Structure
```python
# features/my_feature/main.py
"""
Feature: My Feature Name
Runs in: master2.py (trading logic)
"""

from core.database import get_postgres, postgres_execute

def run():
    """Main entry point for this feature."""
    
    # Read data
    with get_postgres() as conn:
        with conn.cursor() as cursor:
            cursor.execute("""
                SELECT * FROM prices 
                WHERE token = %s 
                ORDER BY timestamp DESC LIMIT 10
            """, ['SOL'])
            prices = cursor.fetchall()
    
    # Process data...
    result = analyze_prices(prices)
    
    # Write result
    if result:
        postgres_execute("""
            INSERT INTO my_results (data, created_at) 
            VALUES (%s, NOW())
        """, [result])
```

### Scheduled Task Registration - master.py (Data Jobs)
```python
# In scheduler/master.py
from get_prices_from_jupiter import fetch_and_store_once

scheduler.add_job(
    fetch_and_store_once,
    trigger='interval',
    seconds=1,
    id='fetch_jupiter_prices',
    name='Fetch prices from Jupiter API',
    executor='realtime'
)
```

### Scheduled Task Registration - master2.py (Trading Jobs)
```python
# In scheduler/master2.py

@track_job("my_feature", "My Feature Description")
def my_feature_job():
    """Job wrapper for my feature."""
    try:
        from features.my_feature.main import run
        run()
    except Exception as e:
        logger.error(f"My feature error: {e}", exc_info=True)

scheduler.add_job(
    my_feature_job,
    trigger='interval',
    seconds=10,
    id='my_feature',
    name='My Feature',
    executor='realtime'
)
```

---

## Migration Status

### âœ… Completed
- PostgreSQL schema created (`scripts/postgres_schema.sql`)
- `core/database.py` - PostgreSQL-only with connection pooling
- `scheduler/master.py` - Direct PostgreSQL writes
- `scheduler/master2.py` - Simplified trading logic (no backfill)
- `scheduler/website_api.py` - Direct PostgreSQL queries
- All trading modules - Updated to PostgreSQL syntax
- All data feed modules - Updated to PostgreSQL syntax

### ğŸ“‹ Architecture Benefits
- **Simpler:** One database, no syncing
- **Faster:** No backfill on restart (3s vs 2h)
- **Persistent:** All data survives restarts
- **Standard:** Industry-standard PostgreSQL tools

---

## Forbidden Practices

### General
âŒ Never use `.bat` files for scheduling
âŒ Never add trading logic to master.py (data ingestion only)
âŒ Never add data ingestion to master2.py (trading logic only)
âŒ Never create duplicate utility files - use `core/`
âŒ Never import `duckdb` - use PostgreSQL only

### Database Access (CRITICAL)
âŒ Never use `?` placeholders - use `%s` in PostgreSQL
âŒ Never use DuckDB syntax (INSERT OR REPLACE, etc.)
âŒ Never cache connections - always use context managers
âŒ Never use string formatting for SQL - use parameterized queries
âŒ Never forget `WITH get_postgres() as conn:` context manager

---

## Critical Reminders for AI Agents

### ğŸ”´ MOST IMPORTANT: PostgreSQL Only
- **ONE PostgreSQL database** shared by all processes
- NO in-memory databases
- NO data syncing or backfill logic
- master.py and master2.py both connect to the same PostgreSQL instance

### ğŸ”´ SQL Syntax
```python
# âœ… CORRECT (PostgreSQL)
cursor.execute("SELECT * FROM table WHERE id = %s", [123])

# âŒ WRONG (DuckDB - don't use)
cursor.execute("SELECT * FROM table WHERE id = ?", [123])
```

### ğŸ”´ Database Access Pattern
```python
# âœ… CORRECT
from core.database import get_postgres, postgres_execute

# Read
with get_postgres() as conn:
    with conn.cursor() as cursor:
        cursor.execute("SELECT ...")
        results = cursor.fetchall()

# Write
postgres_execute("UPDATE ...", [params])
```

### ğŸ”´ Restart Independence
- master.py runs continuously (data feeds must never stop)
- master2.py can restart independently (no data loss)
- website_api.py can restart any time
- All data persists in PostgreSQL

---

## File Locations

| Purpose | Location |
|---------|----------|
| PostgreSQL schema | `scripts/postgres_schema.sql` |
| PostgreSQL config | See `core/config.py` for connection details |
| Job functions | `scheduler/jobs.py` |
| Component runner | `scheduler/run_component.py` |
| Component registry | `scheduler/component_registry.py` |
| Component control | `scheduler/control.py` |
| Website API | `scheduler/website_api.py` |
| Shared code | `core/` |
| Features | `features/` |
| Trading modules | `000trading/` |
| Data feeds | `000data_feeds/` |

---

## Architecture Diagram

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              COMPONENT-BASED ARCHITECTURE                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                 â”‚
â”‚  Each component runs as: python3 scheduler/run_component.py     â”‚
â”‚                                                                 â”‚
â”‚  Data Ingestion:              Trading Logic:                    â”‚
â”‚  - fetch_jupiter_prices       - follow_the_goat                 â”‚
â”‚  - process_price_cycles       - trailing_stop_seller            â”‚
â”‚  - sync_trades_from_webhook   - train_validator                 â”‚
â”‚  - webhook_server (8001)      - update_potential_gains          â”‚
â”‚  - php_server (8000)          - create_new_patterns             â”‚
â”‚  - binance_stream             - create_profiles                 â”‚
â”‚                               - archive_old_data                â”‚
â”‚                               - local_api_5052                  â”‚
â”‚                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                               â”‚
                               â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                POSTGRESQL DATABASE (Shared)                     â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                 â”‚
â”‚  Tables:                                                        â”‚
â”‚  - prices, sol_stablecoin_trades, order_book_features           â”‚
â”‚  - cycle_tracker, wallet_profiles                               â”‚
â”‚  - follow_the_goat_plays, follow_the_goat_buyins                â”‚
â”‚  - scheduler_components, scheduler_component_heartbeats         â”‚
â”‚  - And more...                                                  â”‚
â”‚                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                               â†‘
                               â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      WEBSITE_API.PY                             â”‚
â”‚                       (Flask API)                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                 â”‚
â”‚  Endpoints:                                                     â”‚
â”‚  - /health, /cycles, /buyins, /plays, /profiles                 â”‚
â”‚  - /scheduler/components (list, toggle enable/disable)          â”‚
â”‚  - /scheduler/errors                                            â”‚
â”‚                                                                 â”‚
â”‚  Port: 5051                                                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

End of .cursorrules
