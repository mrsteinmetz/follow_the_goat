================================================================================
PRE-ENTRY FILTER INTEGRATION WITH AUTO PATTERN GENERATOR
================================================================================

## Problem Statement

The auto pattern generator (`000data_feeds/7_create_new_patterns/create_new_paterns.py`)
generates filters based on trail data (buyin_trail_minutes), but these filters
are checked AFTER the pre-entry filter in pattern_validator.py.

The pre-entry filter runs FIRST (lines 1154-1203) and can reject trades before
pattern filters are even evaluated. This means:

1. Pre-entry filter is NOT learned/generated by the auto system
2. Pre-entry filter is HARD-CODED (0.08% threshold)
3. Pattern generator doesn't know about pre-entry requirements

## Solution: Add Pre-Entry Filters to Pattern Generator

We need to make the pattern generator "pre-entry aware" so it can:
1. Analyze pre-entry metrics alongside trail data
2. Generate optimal pre-entry thresholds
3. Store them as special filters in pattern_config_filters
4. Have pattern_validator respect these learned thresholds

## Implementation Steps

### Step 1: Add Pre-Entry Columns to Trade Data

File: `000data_feeds/7_create_new_patterns/create_new_paterns.py`
Location: In `load_trade_data()` function (around line 198)

```python
def load_trade_data(engine, hours: int = 24) -> pd.DataFrame:
    """Load trade data from cache with PRE-ENTRY metrics."""
    
    # ... existing code ...
    
    # Add query to join pre-entry data from buyin_trail_minutes
    query = """
        SELECT 
            b.id AS buyin_id,
            b.followed_at,
            b.potential_gains,
            b.our_profit_loss,
            
            -- Pre-entry metrics (from minute 0, sub_minute 0)
            t0.pre_entry_trend,
            t0.pre_entry_change_1m,
            t0.pre_entry_change_2m,
            t0.pre_entry_change_3m,  -- KEY METRIC
            t0.pre_entry_change_5m,
            t0.pre_entry_change_10m,
            
            -- Signal alignment metrics
            t0.tx_buy_sell_pressure AS entry_buy_pressure,
            t0.wh_net_flow_ratio AS entry_whale_flow,
            t0.pat_breakout_score AS entry_breakout_score
            
        FROM follow_the_goat_buyins b
        LEFT JOIN buyin_trail_minutes t0 
            ON t0.buyin_id = b.id 
            AND t0.minute = 0 
            AND t0.sub_minute = 0
        WHERE b.followed_at >= NOW() - INTERVAL '%s hours'
            AND b.potential_gains IS NOT NULL
    """
    
    # ... rest of function ...
```

### Step 2: Create Pre-Entry Filter Suggestions

Add new function after `analyze_filter_ranges()`:

```python
def analyze_pre_entry_thresholds(df: pd.DataFrame, threshold: float = 0.3) -> Dict[str, Any]:
    """
    Analyze pre-entry metrics to find optimal thresholds.
    
    Returns suggested minimum values for:
    - pre_entry_change_3m (primary)
    - pre_entry_change_1m (momentum check)
    - entry_buy_pressure (signal alignment)
    - entry_whale_flow (whale alignment)
    
    Args:
        df: DataFrame with pre-entry columns and potential_gains
        threshold: Good trade threshold (default 0.3%)
    
    Returns:
        Dict with suggested pre-entry filters
    """
    # Classify trades
    df['is_good'] = df['potential_gains'] >= threshold
    good_df = df[df['is_good'] == True]
    bad_df = df[df['is_good'] == False]
    
    suggestions = {}
    
    # Analyze pre_entry_change_3m (MOST IMPORTANT)
    if 'pre_entry_change_3m' in df.columns:
        # Find threshold that maximizes bad removal while keeping good trades
        good_3m = good_df['pre_entry_change_3m'].dropna()
        bad_3m = bad_df['pre_entry_change_3m'].dropna()
        
        if len(good_3m) > 10 and len(bad_3m) > 10:
            # Try different percentiles of good trades
            for percentile in [10, 15, 20, 25, 30]:
                min_threshold = good_3m.quantile(percentile / 100)
                
                good_kept = (good_3m >= min_threshold).sum() / len(good_3m) * 100
                bad_removed = (bad_3m < min_threshold).sum() / len(bad_3m) * 100
                
                # Accept if removes 30%+ bad trades while keeping 70%+ good
                if bad_removed >= 30 and good_kept >= 70:
                    suggestions['pre_entry_change_3m'] = {
                        'min_value': float(min_threshold),
                        'good_kept_pct': good_kept,
                        'bad_removed_pct': bad_removed,
                        'percentile': percentile,
                        'priority': 'CRITICAL'
                    }
                    break
    
    # Analyze entry_buy_pressure (signal alignment)
    if 'entry_buy_pressure' in df.columns:
        good_pressure = good_df['entry_buy_pressure'].dropna()
        bad_pressure = bad_df['entry_buy_pressure'].dropna()
        
        if len(good_pressure) > 10 and len(bad_pressure) > 10:
            # Minimum acceptable buy pressure (must be positive)
            min_threshold = max(0.0, good_pressure.quantile(0.15))  # 15th percentile
            
            good_kept = (good_pressure >= min_threshold).sum() / len(good_pressure) * 100
            bad_removed = (bad_pressure < min_threshold).sum() / len(bad_pressure) * 100
            
            if bad_removed >= 20:
                suggestions['entry_buy_pressure'] = {
                    'min_value': float(min_threshold),
                    'good_kept_pct': good_kept,
                    'bad_removed_pct': bad_removed,
                    'priority': 'HIGH'
                }
    
    # Analyze entry_whale_flow
    if 'entry_whale_flow' in df.columns:
        good_whale = good_df['entry_whale_flow'].dropna()
        bad_whale = bad_df['entry_whale_flow'].dropna()
        
        if len(good_whale) > 10 and len(bad_whale) > 10:
            min_threshold = good_whale.quantile(0.20)  # 20th percentile
            
            good_kept = (good_whale >= min_threshold).sum() / len(good_whale) * 100
            bad_removed = (bad_whale < min_threshold).sum() / len(bad_whale) * 100
            
            if bad_removed >= 20:
                suggestions['entry_whale_flow'] = {
                    'min_value': float(min_threshold),
                    'good_kept_pct': good_kept,
                    'bad_removed_pct': bad_removed,
                    'priority': 'MEDIUM'
                }
    
    return suggestions
```

### Step 3: Store Pre-Entry Filters in Database

Modify `sync_best_filters_to_project()` to add pre-entry filters:

```python
def sync_best_filters_to_project(engine, combinations: List[Dict[str, Any]], 
                                  project_id: int,
                                  pre_entry_suggestions: Dict[str, Any] = None) -> Dict[str, Any]:
    """Sync filters including pre-entry thresholds."""
    
    # ... existing code to sync pattern filters ...
    
    # Add pre-entry filters if available
    if pre_entry_suggestions:
        logger.info("Adding pre-entry filters...")
        
        for field_name, suggestion in pre_entry_suggestions.items():
            min_value = suggestion['min_value']
            priority = suggestion.get('priority', 'MEDIUM')
            
            try:
                with get_postgres() as conn:
                    with conn.cursor() as cursor:
                        cursor.execute("""
                            INSERT INTO pattern_config_filters
                            (id, project_id, name, section, minute, field_name, field_column,
                             from_value, to_value, include_null, is_active)
                            VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s)
                        """, [
                            90000 + project_id,  # Special ID range for pre-entry filters
                            project_id,
                            f"Pre-Entry: {field_name}",
                            "pre_entry",  # Special section
                            0,  # Always minute 0
                            field_name,
                            field_name,  # field_column same as field_name
                            min_value,  # from_value = minimum threshold
                            999999,  # to_value = infinity (no upper limit)
                            0,  # don't include null
                            1   # active
                        ])
                    conn.commit()
                
                logger.info(f"  Added PRE-ENTRY filter: {field_name} >= {min_value:.4f} "
                           f"({priority} priority)")
            except Exception as e:
                logger.error(f"Failed to insert pre-entry filter {field_name}: {e}")
    
    return {
        "success": True,
        "filters_synced": filters_inserted,
        "pre_entry_filters": len(pre_entry_suggestions) if pre_entry_suggestions else 0,
    }
```

### Step 4: Update Main Generation Function

Modify `generate_auto_filters_main()`:

```python
def generate_auto_filters_main(engine, max_hours: int = 48, is_ratio: bool = False) -> Dict[str, Any]:
    """Main auto filter generation with pre-entry awareness."""
    
    # ... existing code ...
    
    # Step 3: Analyze pre-entry thresholds (NEW)
    logger.info("\n[Step 3b/6] Analyzing pre-entry thresholds...")
    pre_entry_suggestions = analyze_pre_entry_thresholds(df, config['good_trade_threshold'])
    
    if pre_entry_suggestions:
        logger.info(f"Found {len(pre_entry_suggestions)} pre-entry filters:")
        for field, suggestion in pre_entry_suggestions.items():
            logger.info(f"  {field}: >= {suggestion['min_value']:.4f} "
                       f"(removes {suggestion['bad_removed_pct']:.1f}% bad)")
    else:
        logger.warning("No pre-entry filters generated")
    
    # ... rest of existing code ...
    
    # Step 5: Sync filters (pass pre_entry_suggestions)
    sync_result = sync_best_filters_to_project(
        engine, 
        combinations, 
        project_id,
        pre_entry_suggestions=pre_entry_suggestions  # NEW
    )
```

### Step 5: Update Pattern Validator to Use Dynamic Thresholds

File: `000trading/pattern_validator.py`
Location: Lines 1154-1203 (pre-entry check)

```python
# CRITICAL PRE-ENTRY PRICE MOVEMENT CHECK
if PRE_ENTRY_AVAILABLE:
    try:
        logger.debug(f"Checking pre-entry price movement for buyin #{buyin_id}")
        
        # Get buyin details
        with get_postgres() as conn:
            with conn.cursor() as cursor:
                cursor.execute("""
                    SELECT followed_at, our_entry_price
                    FROM follow_the_goat_buyins
                    WHERE id = %s
                """, [buyin_id])
                buyin_info = cursor.fetchone()
        
        if buyin_info:
            entry_time = buyin_info['followed_at']
            entry_price = float(buyin_info['our_entry_price'])
            
            # Calculate pre-entry metrics
            pre_entry_metrics = calculate_pre_entry_metrics(entry_time, entry_price)
            
            # Get dynamic threshold from project filters (if exists)
            min_change_3m = 0.20  # Default (increased from 0.08)
            
            if projects_to_validate:
                # Check for pre-entry filter in project
                for project_id in projects_to_validate:
                    with get_postgres() as conn:
                        with conn.cursor() as cursor:
                            cursor.execute("""
                                SELECT from_value
                                FROM pattern_config_filters
                                WHERE project_id = %s
                                  AND section = 'pre_entry'
                                  AND field_name = 'pre_entry_change_3m'
                                  AND is_active = 1
                                LIMIT 1
                            """, [project_id])
                            result = cursor.fetchone()
                            
                            if result and result['from_value']:
                                min_change_3m = float(result['from_value'])
                                logger.info(f"Using learned pre-entry threshold: {min_change_3m:.3f}%")
                                break
            
            # Check if should enter
            should_enter, reason = should_enter_based_on_price_movement(
                pre_entry_metrics, 
                min_change_3m=min_change_3m  # Use dynamic or default threshold
            )
            
            log_pre_entry_analysis(pre_entry_metrics, logger)
            
            if not should_enter:
                logger.info(f"✗ Buyin #{buyin_id} REJECTED by pre-entry filter: {reason}")
                return {
                    "buyin_id": buyin_id,
                    "timestamp": datetime.utcnow().isoformat(),
                    "decision": "NO_GO",
                    "reason": f"Pre-entry price movement filter: {reason}",
                    "pre_entry_metrics": pre_entry_metrics,
                    "pre_entry_threshold_used": min_change_3m,  # NEW
                    "schema_source": "pre_entry_filter",
                    "validator_version": "v4_pre_entry_filter",
                }
            else:
                logger.info(f"✓ Buyin #{buyin_id} passes pre-entry filter: {reason}")
        
    except Exception as e:
        logger.error(f"Error in pre-entry check: {e}", exc_info=True)
```

## Testing the Integration

### Test Script

Create: `/root/follow_the_goat/wallet_analysis/test_auto_pre_entry.py`

```python
"""
Test if auto pattern generator correctly learns pre-entry thresholds
"""
import sys
from pathlib import Path
PROJECT_ROOT = Path(__file__).parent.parent
sys.path.insert(0, str(PROJECT_ROOT))

from core.database import get_postgres

def main():
    print("=" * 80)
    print("TESTING AUTO PRE-ENTRY FILTER GENERATION")
    print("=" * 80)
    
    project_id = 5  # Your auto-filters project ID
    
    # Check for pre-entry filters in database
    print(f"\nChecking project {project_id} for pre-entry filters...")
    
    with get_postgres() as conn:
        with conn.cursor() as cursor:
            cursor.execute("""
                SELECT 
                    name,
                    field_name,
                    from_value,
                    to_value,
                    section
                FROM pattern_config_filters
                WHERE project_id = %s
                  AND (section = 'pre_entry' OR field_name LIKE 'pre_entry%')
                ORDER BY field_name
            """, [project_id])
            pre_entry_filters = cursor.fetchall()
    
    if pre_entry_filters:
        print(f"\n✓ Found {len(pre_entry_filters)} pre-entry filters:")
        for f in pre_entry_filters:
            print(f"  {f['field_name']}: >= {f['from_value']:.4f}")
    else:
        print("\n✗ NO pre-entry filters found!")
        print("  Pattern generator hasn't been updated yet")
        print("  Or no pre-entry data available in trail_minutes")
    
    # Check if trail data has pre-entry columns
    print("\nChecking if trail data includes pre-entry metrics...")
    with get_postgres() as conn:
        with conn.cursor() as cursor:
            cursor.execute("""
                SELECT column_name
                FROM information_schema.columns
                WHERE table_name = 'buyin_trail_minutes'
                  AND column_name LIKE 'pre_entry%'
                ORDER BY column_name
            """)
            pre_entry_columns = cursor.fetchall()
    
    if pre_entry_columns:
        print(f"\n✓ Trail data has {len(pre_entry_columns)} pre-entry columns:")
        for col in pre_entry_columns:
            print(f"  - {col['column_name']}")
    else:
        print("\n✗ Trail data MISSING pre-entry columns!")
        print("  Need to regenerate trails with pre_entry_price_movement.py")

if __name__ == "__main__":
    main()
```

Run: `python3 wallet_analysis/test_auto_pre_entry.py`

## Summary

The solution has 5 key changes:

1. **Load pre-entry data** - Add pre_entry_change_3m to trade analysis
2. **Analyze thresholds** - Find optimal pre-entry minimum values
3. **Store as filters** - Save to pattern_config_filters with section='pre_entry'
4. **Dynamic validation** - pattern_validator reads learned threshold
5. **Fallback to 0.20%** - If no learned threshold, use improved default

This makes the pre-entry filter part of the auto-learning system while
maintaining backward compatibility.

================================================================================
Created: 2026-02-03
Status: DESIGN COMPLETE - Ready for implementation
Next: Implement changes in create_new_paterns.py and pattern_validator.py
================================================================================
